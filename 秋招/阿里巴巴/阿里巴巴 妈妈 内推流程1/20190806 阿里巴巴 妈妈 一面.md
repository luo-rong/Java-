
### Java
#### ~~1. `final` `finally` `finalize`区别~~

#### 2. `HashMap`基于什么数据结构实现
1. JDK1.8以前
    1. 数据结构：链表散列，数组+链表
    2. 键值对内部类：`Entry`
2. JDK1.8及以后
    1. 数据结构：数组+链表+红黑树（红黑树可提高效率）
    2. 键值对内部类：`Node`&`TreeNode`
        ```java
        static class Node<K,V> implements Map.Entry<K,V>{}
        static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V>{}
        ```

#### 3. `HashMap`如何处理hash冲突
链地址法
1. 计算出hash值，计算位置（因为n为table长度，为2的幂，故可用位运算计算余数）`i = (n - 1) & hash`
2. 若当前发生hash冲突
    1. 找到相同key，则用带插入值覆盖原有值，返回旧值
    2. 未找到相同key，则插入node，返回null
        1. 红黑树：添加节点
        2. 链表：在尾部插入

#### 4. `HashMap` `CurrentHashMap` `LinkedHashMap` `HashTable`区别
接口`java.util.Map`，Map主要用于存储健值对，根据键得到值，因此不允许键重复（重复则覆盖），但允许值重复
1. Hashmap
    ```java
    public class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable {}
    ```
    最常用的Map，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。HashMap最多只允许一条记录的键为`Null`，允许多条记录的值为`Null`；`HashMap`不支持线程的同步，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要同步，可以用`Collections`的`synchronizedMap`方法使`HashMap`具有同步的能力，或者使用`ConcurrentHashMap`
2. `HashTable`
    ```java
    public class Hashtable<K,V> extends Dictionary<K,V> implements Map<K,V>, Cloneable, java.io.Serializable {}
    ```
    与HashMap类似，它继承自`Dictionary`类，不同的是：它不允许记录的键或者值为`Null`，它支持线程的同步，即任一时刻只有一个线程能写`Hashtable`，因此也导致了`Hashtable`在写入时会比较慢
3. `LinkedHashMap`
    ```java
    public class LinkedHashMap<K,V> extends HashMap<K,V> implements Map<K,V> {}
    ```
    `HashMap`的一个子类，保存了记录的插入顺序，在用`Iterator`遍历`LinkedHashMap`时，先得到的记录肯定是先插入的．也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比`HashMap`慢，不过有种情况例外，当`HashMap`容量很大，实际数据较少时，遍历起来可能会比`LinkedHashMap`慢，因为`LinkedHashMap`的遍历速度只和实际数据有关，和容量无关，而`HashMap`的遍历速度和容量有关
4. `ConcurrentHashMap`
    ```java
    public class ConcurrentHashMap<K,V> extends AbstractMap<K,V> implements ConcurrentMap<K,V>, Serializable {}
    public interface ConcurrentMap<K, V> extends Map<K, V> {}
    ```
    不允许key/value为空，`Concurrenthashmap`线程安全
    1. JDK1.7中采用`Segment`+`HashEntry`实现，lock加在`Segment`上
    2. JDK1.8中采用`Node`+`CAS`+`Synchronized`实现

#### 5. `CurrentHashMap`实现线程安全的关键（JDK1.7 分段锁）
[ConcurrentHashMap实现原理及源码分析](https://www.cnblogs.com/chengxiao/p/6842045.html)

JDK1.7中采用`Segment`+`HashEntry`实现，lock加在`Segment`上。`Segment`继承了`ReentrantLock`，所以它就是一种可重入锁。在`ConcurrentHashMap`，一个`Segment`就是一个子哈希表，`Segment`里维护了一个`HashEntry`数组，并发环境下，对于不同`Segment`的数据进行操作是不用考虑锁竞争的，对于同一个Segment的操作才需考虑线程同步
1. `get()`方法：先定位`Segment`，再定位`HashEntry`。`get()`方法无需加锁，由于其中涉及到的共享变量都使用`volatile`修饰，`volatile`可以保证内存可见性，所以不会读取到过期数据
2. `put()`方法
    1. 定位segment并确保定位的Segment已初始化
    2. 调用Segment的put方法：`tryLock()`不成功时会遍历定位到的`HashEnry`位置的链表（遍历主要是为了使CPU缓存链表），若找不到，则创建`HashEntry`。`tryLock()`一定次数后，则lock。若遍历过程中，由于其他线程的操作导致链表头结点变化，则需要重新遍历

#### 6. 线程安全怎么理解
当多个线程访问某个方法时，不管你通过怎样的调用方式或者说这些线程如何交替的执行，我们在主程序中不需要去做任何的同步，这个类的结果行为都是我们设想的正确行为，那么我们就可以说这个类是线程安全的。

#### 7. 线程池有什么用，为什么要使用线程池
1. 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 
2. 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能执行。
3. 提高线程的可管理性，线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。

#### 8. `Synchronized` `ReentrantLock`区别
1. 相似点：都是加锁方式同步，而且都是阻塞式的同步，也就是说当如果一个线程获得了对象锁，进入了同步块，其他访问该同步块的线程都必须阻塞在同步块外面等待，而进行线程阻塞和唤醒的代价是比较高的
2. 功能区别
    1. `Synchronized`是java语言的关键字，是原生语法层面的互斥，需要jvm实现
    2. `ReentrantLock`它是JDK1.5之后提供的API层面的互斥锁，需要`lock()`和`unlock()`方法配合`try/finally`语句块来完成
3. 便利性
    1. `Synchronized`的使用比较方便简洁，并且由编译器去保证锁的加锁和释放
    2. `ReenTrantLock`需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在`finally`中声明释放锁
4. 锁的细粒度和灵活度：很明显`ReenTrantLock`优于`Synchronized`
5. 性能的区别：在`Synchronized`优化以前，`synchronized`的性能是比`ReenTrantLock`差很多，但是自从`Synchronized`引入了偏向锁、轻量级锁（自旋锁）后，两者的性能就差不多了。（在两种方法都可用的情况下，官方甚至建议使用`synchronized`）
    > 其实synchronized的优化感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。

#### ~~9. `String` `StringBuffer` `StringBuilder`区别~~

#### 10. CAS
CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。

CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B，具体过程：
1. 在内存地址V当中，存储着值为10的变量
2. 此时线程1想要把变量的值增加1。对线程1来说，旧的预期值A=10，要修改的新值B=11
3. 在线程1要提交更新之前，另一个线程2抢先一步，把内存地址V中的变量值率先更新成了11
4. 线程1开始提交更新，首先进行A和地址V的实际值比较Compare，发现A不等于V的实际值，提交失败
5. 线程1重新获取内存地址V的当前值，并重新计算想要修改的新值。此时对线程1来说，A=11，B=12。这个重新尝试的过程被称为自旋
6. 这一次比较幸运，没有其他线程改变地址V的值。线程1进行Compare，发现A和地址V的实际值是相等的
7. 线程1进行SWAP，把地址V的值替换为B，也就是12
从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。

CAS的缺点：
1. CPU开销较大。在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。
2. 不能保证代码块的原子性。CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了

#### ~~11. BIO与NIO、AIO的区别~~

### 操作系统
#### ~~1. 死锁~~

#### 2. 银行家算法
[操作系统：银行家算法（避免死锁）](https://blog.csdn.net/s634772208/article/details/46324257)

#### 3. 分页算法，FIFO、LRU
1. FIFO：先进先出页面置换算法
2. LRU：Least Recently Used 最近最少使用算法

### 数据库
#### 1. 数据库事务如何实现

### 网络
#### 1. 从在浏览器输入网址到返回页面，经历了什么
[What really happens when you navigate to a URL](http://igoro.com/archive/what-really-happens-when-you-navigate-to-a-url/)

1. 准备:DHCP/UDP/IP和以太网
    
    启动主机MacBook,用一根以太网电缆连接到学校的以太网交换机,交换机又与学校的路由器相连.学校的这台路由器与一个ISP链接,此IPS还提供了DNS服务.所以DNS服务器驻留在Comcast网络中而不是学校网络中.假设DHCP服务器运行在路由器中.
    
    当主机与网络连接时,没有IP地址就不能做任何事情,例如下载一个Web网页.所以主机采取的一个网络相关的动作是运行DHCP协议,以从本地的DHCP服务器获得一个IP地址以及其他信息.
    1. 系统生成一个DHCP请求报文(动态主机配置协议),并将这个报文放入具有目的地端口67(DHCP服务器)和源端口68(DHCP客户)的UDP报文段.该UDP报文段则被放置在一个具有广播IP目的地址(255.255.255.255)和源IP地址(0.0.0.0)的IP数据报中,因为此时主机还不具有IP地址.
    2. 包含DHCP请求报文的IP数据报则被放置在以太网帧中.该以太网帧具有目的MAC地址(FF:FF:FF:FF:FF:FF),使该帧将广播到与交换机连接的所有设备,如果顺利的话也包括DHCP服务器(路由器),该帧的源MAC地址是00:16:D3:23:68:8A.
    3. 包含DHCP请求的广播以太网帧是第一个由MacBook发到以太网交换机的帧,该交换机在所有的出端口广播帧,包括连接到路由器的端口.
    4. 路由器在它的具有MAC地址00:22:6B:45:1F的接口接收到该广播的以太网帧,该帧中包含DHCP请求,并且从该以太网帧中抽取出IP数据包.该数据报的广播目的地址指示了这个IP数据报应当由该结点的高层协议处理,因此该数据报的载荷一个UPD报文段被分解向上达到UDP,DHCP请求报文从此UDP报文段中抽取出来,此时DHCP服务器有了DHCP请求报文.
    5. 假设运行的路由器中的DHCP服务器能够以CIDR(无类别域间路由选择)块68.85.2.0/24分配IP地址.所以,MacBook地址在Comcast地址块中.假设DHCP服务器分配地址68.85.2.101给MacBook.DHCP服务器生成包含这个IP地以及DNS服务器的IP(68.87.71.226)/默认网关路由器的IP地址(68.85.2.1)和子网块(68.85.2.0/24网络掩码)的一个DHCP ACK报文.该DHCP报文被放入一个UDP报文段中,UDP报文段被放入一个IP数据报中,IP数据报再被放入一个以太网帧中.一个以太网帧的源MAC地址是路由器连接到归属网络时接口的MAC地址(00:22:6B:45:1F:1B),目的MAC地址是MacBook的MAC地址(00:16:D3:23:68:8A).
    6. 包含DHCP ACK的以太网帧由路由器发给交换机.因为交换机是自学习的,并且先前从DHCP请求的以太网帧,所以交换机知道寻址到00:16:D3:23:68:8A的帧仅通过MacBook的输出端口转发.
    7. MacBook收到包含DHCP ACK的以太网帧,从该以太网帧中抽取IP数据报,从IP数据报中抽取UDP报文段,从UDP报文段中抽取DHCP ACK报文.MacBook则记录下它的IP地址和它的DNS服务器的IP地址.它还在其IP转发表中安装默认网关地址.

2. 仍在准备: DNS和ARP
    
    当在浏览器把www.goole.com的URL输入到Web浏览器中时,开启了一串事件,这将导致谷歌主页最终显示在Web浏览器上.Web浏览器通过生成一个TCP套接字开始该过程,套接字用于向www.google.com发送HTTP请求.为了生成该套接字,需要知道www.google.com的IP地址.需要使用DNS协议提供这种名字到IP地址的转换服务.
    
    8. MacBook操作系统因此生成一个DNS查询报文,将字符串www.google.com放入DNS报文的问题段中.该DNS报文则放置在一个具有53号(DNS服务器)目的端口的UDP报文段中.该UDP报文段则被放入具有IP目的地址68.87.71.226和源IP地址68.85.2.101的IP数据报中.
    9. MacBook则将包含DNS请求报文的数据报IP放入到一个以太网帧中.该帧将发送到网络中的网关路由器.然而,即使MacBook虽然获取了网关路由器的IP地址(68.85.2.1),但仍不知道该网关路由器的MAC地址.为了获得该网关路由器的MAC地址,需要使用ARP(地址解析协议)协议.
    10. MacBook生成一个具有目的IP地址68.85.2.1(默认网关)的ARP查询报文,将该ARP报文防止在一个具有广播目的地址(FF:FF:FF:FF:FF:FF:FF)的以太网帧中,并向交换机发送该以太网帧,交换机将该帧交付给所有连接的设备,包括网关路由器.
    11. 网关路由器在接口上收到包含该ARP查询报文的帧,发现ARP报文中目的地址IP地址68.85.2.1匹配接口的IP地址.网关路由器因此准备一个ARP回答,指示它的MAC地址00:22:6B:45:1F:1B对应地址.68.85.2.1,它将ARP回答放在一个以太网帧中,其目的地址为00:16:D3:23:68:8A,并向交换机发送该帧,再由交换机将该帧交付给MacBook.
    12. MacBook接收包含ARP回答报文的帧,并从ARP回答报文中抽取网关路由器的MAC地址(00:22:6B:45:1F:1B)
    13. MacBook能够包含DNS查询的以太网帧寻址到网关路由器的MAC地址.注意,该帧中的IP数据报具有IP目的地址68.87.71.226(DNS服务器),而该帧具有目的地址00:22:6B:45:1F:1B(网关路由器).MacBook像交换机发送包含DNS报文的帧,交换机将该帧交付给网关路由器.
3. 仍在准备：域内路由选择到DNS服务器
    14. 网关路由器接收该帧并抽取包含DNS查询的IP数据报。路由器查找该数据报的目的地址（68.87.71.226），并根据其转发表决定该数据报应当发送到Comcast网络最左侧的路由器。
    15. 在Comcast网络中最左侧的路由器接收到该帧，抽取IP数据报，检查该数据报的目的地址（68.87.71.226），并根据其转发表确定出接口，经过该接口朝着DNS服务器转发数据报，而转发表已经根据域内协议以及金特网的域间协议BGP所填写。
    16. 最终包含DNS查询的IP数据报到达了DNS服务器。DNS服务器抽取出DNS查询报文，在它的DNS数据库中查找名字www.google.com，找到包含对应www.google.com的IP地址（64.233.169.105）的DNS源记录。（假设是当前缓存在DNS服务器中）。这种缓存数据源于google.com权威DNS服务器。该DNS服务器形成了一个包含这种主机名到IP地址映射的DNS回答报文，将该DNS回答报文放入UDP报文段中，该报文段放入寻址（68.85.2.101）的IP数据报中。该数据报将通过路由器反向转发到学校的路由器，并从这里进过以太网交换机到MacBook的主机。
    17. MacBook主机从DNS报文中取出服务器www.google.com的IP地址。
4. Web客户-服务器交互：TCP和HTTP
    18. 既然MackBook有了www.google.com的IP地址，它能够生成TCP套接字，该套接字将用于向www.google.com发送HTTP GET报文。当生成TCP套接字时，MacBook的TCP必须首先与www.google.com中的TCP执行三次握手。MacBook因此首先生成一个具有目的端口80（针对HTTP的）的TCP SYN报文段，将该TCP报文段放置在具有目的IP地址(64.233.169.105 www.google.com)的IP数据报中，将该数据报放置在MAC地址为00:22:6B:45:1F:1B（网关路由器）的帧中，并向交换机发送该帧。
    19. 在学校网络，Comcast网络和谷歌网络中的路由器朝着www.google.com转发包含TCP SYN的数据报，使用每台路由器中的转发表。支配分组经comcast和 谷歌网络之间域间链路转发的路由器转发表项，是由BGP(自治系统间路由选择)协议决定的。
    20. 最终，包含TCP SYN的数据报到达www.google.com。从数据报抽取出TCP SYN报文并分解到与端口80相联系的欢迎套接字。然后产生一个TCP SYNACK报文段，将其放入想MacBook寻址的一个数据报中，最后放入链路层帧中，该链路适合将www.google.com链接到第一跳路由
    21. 包含TCP SYNACK报文段的数据报通过谷歌，comcast和学校网络，最终达到MacBook的以太网卡。数据报在操作系统中分解到TCP套接字，从而进入链接状态
    22. 现在准备向www.google.com发送字节了，浏览器生成包含获取的URL的HTTP GET报文。HTTP GET报文则写入套接字，其中GET报文成为一个TCP报文段的载荷。该TCP报文段放入一个IP数据报中，并交付到www.google.com
    23. 在www.google.com的HTTP服务器从TCP套接字中读取HTTP GET报文，生成一个HTTP响应报文，将请求的Web网页放入到HTTP响应体中，并报文发送进TCP套接字中
    24. 包含HTTP回答报文的数据报通过谷歌，comcast和学校网络进行转发，到达MacBook。浏览器从套接字中读取HTTP响应，从HTTP响应体中抽取Web网页的html，并最终显示了web网页。

#### ~~2. TCP三次握手~~

#### 3. TCP链接通道里有什么，报文包含什么内容
[TCP报文格式详解](https://blog.csdn.net/mary19920410/article/details/58030147)

### JVM
#### 1. JVM内存模型，垃圾回收回收的是哪部分
*《深入理解Java虚拟机》P39 2.2*
区域 | 是否隔离 | 异常
---|---|---
程序计数栈 | 私有 | 唯一不会抛出OutOfMemoryError异常
Java虚拟机栈 | 私有 | OutOfMemoryError（无法申请到足够内存）；StackOverFlowError（请求栈深度大于虚拟机允许深度）
本地方法栈 | 私有 | OutOfMemoryError（无法申请到足够内存）；StackOverFlowError（请求栈深度大于虚拟机允许深度）
Java堆 | 共享 | OutOfMemoryError（堆中没有完成内存分配且堆无法再扩展）
方法区 | 共享 | OutOfMemoryError（无法满足内存分配需求）
1. 程序计数栈：一块较小的内存空间，是当前线程所执行的字节码的行号指示器。程序计数器只为执行java方法服务，执行Native方法时程序计数器为空
2. Java虚拟机栈：生命周期与线程相同，每个方法在执行的同时都会创建一个栈帧（方法运行时的基础数据结构）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
3. 本地方法栈：与虚拟机栈所发挥的作用是非常相似的，虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务
4. Java堆：在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”
5. 方法区：Non-Heap（非堆），各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据

#### 2. Java堆内存分代管理
1. 新生代：
    1. Eden空间：对象优先在Eden分配，空间不足时，虚拟机将发起一次Minor GC
    2. From Survivor空间、To Survivor空间：在Minor GC时交替使用，达到一定次数后，对象会晋升到老年代。如果Minor GC后仍存活的对象无法放入Survivor，则通过分担带包机制提前将对象转移到老年代
2. 老年代：大对象（需要大量连续内存空间）直接进入老年代；长期存活的对象进入老年代，对象每“熬过”一次Minor GC年龄增加一岁，到一定程度（默认为15岁）则晋升到老年代
3. 永久代：存储类定义、结构、字段、方法（数据及代码）以及常量在内的类相关数据
    
    > JDK 1.8中永久代被元空间（Metaspace）取代。两者本质类似，都是对JVM规范中方法区的实现，最大区别是：永久代的大小很难确定，对永久代的调优过程非常困难；元空间并不在虚拟机中，而是使用本地内存，最大可分配空间就是系统可用内存空间

#### 3. 垃圾回收算法
*《深入理解Java虚拟机》P69 3.3*
1. 标记-清除算法：回收老年代。最基础的收集算法，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，标记完成后统一回收所有被标记的对象

    后续的收集算法都是基于这种思路并对其不足进行改进而得到的。它的主要不足有两个：
    1. 效率问题，标记和清除两个过程的效率都不高；
    2. 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作
    ![image](https://note.youdao.com/yws/public/resource/be02344987843483827564c4dc494b13/xmlnote/1E6DF344CF02413F81DE0C00318B9DD5/7120)
2. 复制算法：回收新生代。为了解决效率问题，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价太高，将内存缩小为了原来的一半
    > 将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的，HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保

    ![image](https://note.youdao.com/yws/public/resource/be02344987843483827564c4dc494b13/xmlnote/6FF30D42ABA34313A1D1C1C2D1A370F0/7124)
3. 标记-整理算法：回收老年代。标记过程仍然与“标记-清除”算法一样，标记完成后让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存
    > 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法

    ![image](https://note.youdao.com/yws/public/resource/be02344987843483827564c4dc494b13/xmlnote/A8E7733C7BCF4802AFDAD88E3108DF23/7132)
4. 分代收集算法：当前商业虚拟机的垃圾收集都采用“分代收集”算法，根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法
    1. 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集
    2. 老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收

#### 4. 解释ClassLoader，类加载器有几种，类加载器加载顺序
*《深入理解Java虚拟机》P227 7.4*
1. 类加载器用于实现类的加载动作，它在Java程序中起到的作用却远远不限于类加载阶段。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。也就是说，比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。
2. Java自带的三种类加载器：
    加载器 | 名称 | 加载目录
    ---|---|---
    ClassLoader | BootStrap启动类加载器 | <JAVA_HOME>/lib
    ExtClassLoader | 扩展类加载器 | <JAVA_HOME>/lib/ext
    AppClassLoader | 应用程序类加载器 | java -classpath
3. 双亲委派模式：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载

    ![image](https://note.youdao.com/yws/public/resource/be02344987843483827564c4dc494b13/xmlnote/7BD96F10EE194313B492B8C7DA8224F4/7363)
    
    双亲委派模式的好处：
    1. 避免类的重复加载
    2. 避免java核心api被串改（如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，可以正常编译，但永远无法被加载运行）

#### 5. 哪个框架破坏了双亲委派模式
*《深入理解Java虚拟机》P233*

典型的打破双亲委派模型的框架和中间件有tomcat与osgi
1. 第一次“被破坏”：发生在双亲委派模型出现之前，即JDK 1.2发布之前。由于双亲委派模型在JDK 1.2之后才被引入，而类加载器和抽象类java.lang.ClassLoader则在JDK 1.0时代就已经存在，面对已经存在的用户自定义类加载器的实现代码，Java设计者引入双亲委派模型时不得不做出一些妥协
2. 第二次“被破坏”：由这个模型自身的缺陷所导致的，双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），基础类之所以称为“基础”，是因为它们总是作为被用户代码调用的API，但世事往往没有绝对的完美，可能存在基础类又要调用回用户的代码。为了解决这个问题，引入了一个不太优雅的设计：线程上下文类加载器
3. 第三次“被破坏”：由于用户对程序动态性的追求而导致的。在OSGi环境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，的类查找可能是在平级的类加载器中进行

#### 6. 类的生命周期（类加载过程）
*《深入理解Java虚拟机》P214 7.3*

类的加载：将编译好的class类文件中的字节码读入到内存中，将其放在方法区内创建对应的class对象，类的加载分为：加载、验证、准备、解析、初始化。加载、验证、准备、初始化和卸载这5个阶段的顺序是确定的。

![image](WEBRESOURCEe86b40f70a237a69ae1a731224d1be27)

1. 加载：
    1. 通过一个类的全限定名来获取定义此类的二进制字节流
    2. 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构
    3. 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口
    > 注意这里不一定非得要从一个Class文件获取，这里既可以从ZIP包中读取（比如从j包和war包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将JSP文件转换成对应的Class类）
2. 验证：重要但不一定必要（对程序运行期没有影响），若所运行的全部代码都已经被反复使用和验证过，那么在实施阶段可关闭类验证，缩短虚拟机类加载的时间。完成四个阶段的检验动作：
    1. 文件格式（通过文件格式验证后，字节流进入内存的方法区中进行存储）
    2. 元数据（检查类）
    3. 字节码（检查方法体）
    4. 符号引用
3. 准备：在方法区中为类变量（被static修饰的变量，不包含final修饰的变量，final修饰的变量在编译时就已分配赋值）分配内存并设置类变量初始值（零值），而非代码中的具体值（代码中值的赋值将在初始化阶段执行）
4. 解析：虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。虚拟机规范之中并未规定解析阶段发生的具体时间，执行前解析即可
5. 初始化：真正开始执行类中定义的Java程序代码（或者说是字节码），根据程序员通过程序制定的主观计划去初始化类变量和其他资源。有且仅有以下五种情况，如果类没有初始化则会先触发其初始化：
    1. 遇到new、getstatic、setstatic或者invokestatic这4个字节码指令时：使用new关键字实例化对象；读取或设置一个类的静态字段（final修饰的字段除外）；调用一个类的静态方法
    2. 使用java.lang.reflect包的方法对类进行反射调用的时
    3. 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化
    4. 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个类），虚拟机会先初始化这个主类
    5. 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化

### Spring
#### 1. 为什么要用Spring框架开发
*《Spring 3.x》P5 1.3*
1. 方便解耦，简化开发：通过IoC容器，可以将对象之间的依赖关系交由Spring进行控制，避免硬编码所造成的过度程序耦合。不必再为单实例模式类、属性文件解析等这些很底层的需求编写代码，可以更专注于上层的应用
2. AOP编程的支持：通过Spring提供的AOP功能，方便进行面向切面的编程，许多不易用传统OOP实现的功能可以通过AOP实现
3. 声明事物的支持：通过声明式方式灵活地进行事务的管理，提高开发效率和质量
4. 方便程序的测试：可以用非容器依赖的编程方式进行几乎所有的测试工作，让测试更方便。例如：可以用Junit4通过注解方便的测试
5. 方便集成各种优秀框架：降低各种框架的使用难度，Spring提供了对各种优秀框架的直接支持（如Struts,Hibernate、Hessian、Quartz）
6. 降低Java EE API的使用难度：对很多难用的Java EE API（如JDBC，JavaMail，远程调用）提供了封装层，降低其使用难度
7. 源码是经典学习范例：Spring的源码设计精妙、结构清晰，体现着对Java设计模式灵活运用以及对Java技术的高深造诣。Spring框架源码是Java技术的最佳实践范例

#### 2. IoC AOP 理解
*《Spring 3.x》P41 3.1 & 《Spring 3.x》P174 6.1*

Spring最成功的是其提出的理念，而不是技术本身。它所依赖的两个核心理念，一个是控制反转（IoC），另一个是面向切面编程（AOP）
1. IoC：Spring容器的内核，AOP、声明式事务等功都以此为基础。它涉及代码解耦、设计模式、代码优化等问题的考量。
    
    某一接口具体实现类的选择控制权从调用类中移除，转交给第三方决定。也就是“依赖注入”，让调用类对某一接口实现类的依赖关系有第三方注入，以移除调用类对某一接口实现类的依赖
    1. IoC的类型（Spring支持构造函数注入和属性注入）：
        1. 构造函数注入：在构造函数注入中，我们通过调用类的构造函数，将接口实现类通过构造函数变量传入
        2. 属性注入：属性注入可以有选择地通过Setter方法完成调用类所需依赖的注入，更加灵活方便
        3. 接口注入： 将调用类所有依赖注入的方法抽取到一个接口中，调用类通过实现该接口提供相应的注入方法。由于通过接口注入需要额外声明一个接口，增加了类的数目，而且它的效果和属性注入并无本质区别，因此我们不提倡采用这种方式
    2. 通过容器完成依赖关系的注入：用一个第三方的容器（Spring）帮助完成类的初始化与装配工作，完成底层实现类的实例化、依赖关系装配等工作。Spring通过配置文件或注解描述类和类之间的依赖关系，自动完成类的初始化和依赖注入的工作
2. AOP：面向切面编程，作为OOP的有益补充，AOP的应用场合有限制，它一般只使用与那些具有横切逻辑的应用场合：如性能检测，访问控制，事物管理以及日志记录。AOP实现的关键就在于AOP框架自动创建的AOP代理，AOP代理则可分为静态代理和动态代理两大类：
    1. 静态代理是指使用AOP框架提供的命令进行编译，从而在编译阶段就可生成AOP代理类，因此也称为编译时增强（AspectJ）
    2. 动态代理则在运行时借助于JDK动态代理、CGLIB等在内存中“临时”生成AOP动态代理类，因此也被称为运行时增强（Spring AOP）

#### 3. 什么是动态代理和静态代理
1. 静态代理是指使用AOP框架提供的命令进行编译，从而在编译阶段就可生成AOP代理类，因此也称为编译时增强（AspectJ）
2. 动态代理则在运行时借助于JDK动态代理、CGLIB等在内存中“临时”生成AOP动态代理类，因此也被称为运行时增强（Spring AOP）

#### 4. 动态代理的实现
*《Spring 3.x》P181 6.2.2 & 《Spring 3.x》P184 6.2.3*
1. JDK动态代理：基于接口的代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。核心是InvocationHandler接口和Proxy类，具体实现原理：
    1. 实现`InvocationHandler`接口创建自己的编织器。重写`invoke()`方法，反射机制调用业务类的目标方法
    2. 实例化一个编织器`handler`。通过构造方法传入希望被代理的目标对象
    3. 实例化`Proxy`类。通过静态方法`newProxyInstance()`为编织了业务逻辑和增强逻辑的`handler`创建一个符合业务类接口的代理实例
2. CGLIB动态代理：基于继承的代理。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。采用非常底层的字节码技术：
    1. 实现`MethodInterceptor`接口创建代理创建器`CglibProxy`
        1. 实现`getProxy()`方法。设置需要创建子类的类（业务类），通过字节码技术动态创建子类实例
        2. 实现`intercapt()`方法。拦截父类所有方法的调用，通过代理类调用父类中的方法
    2. 实例化一个代理创建器`proxy`。通过动态生成子类的方法（`getProxy()`）创建代理类

    关于两者之间的性能：
    1. CGLib所创建的动态代理对象在实际运行时候的性能要比JDK动态代理高不少，有研究表明，大概要高10倍
    2. 但是CGLib在创建对象的时候所花费的时间却比JDK动态代理要多很多，有研究表明，大概有8倍的差距
    3. 因此，对于singleton的代理对象或者具有实例池的代理，因为无需频繁的创建代理对象，所以比较适合采用CGLib动态代理，反之，则比较适用JDK动态代理

#### 数据结构
#### 1. 红黑树插入元素的过程（变色）
[红黑树](https://wikipedia.hk.wjbk.site/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91)

自平衡的查找树

1. 性质
    
    红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求（保证了红黑树从根到叶子的最长路径不会超过最短路径的2倍）：
    1. 节点是红色或黑色
    2. 根节点是黑色
    3. 每个叶子节点都是黑色的空节点（NIL节点）
    4. 每个红色节点的两个子节点都是黑色(从每个叶子到根的所有路径上不能有两个连续的红色节点)
    5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点
2. 插入
    1. 情形1：新节点N位于树的根上，没有父节点。在这种情形下，我们把它重绘为黑色以满足性质2。因为它在每个路径上对黑节点数目增加一，性质5符合
    2. 情形2：新节点的父节点P是黑色，所以性质4没有失效（新节点是红色的）。在这种情形下，树仍是有效的。性质5也未受到威胁，尽管新节点N有两个黑色叶子子节点；但由于新节点N是红色，通过它的每个子节点的路径就都有同通过它所取代的黑色的叶子的路径同样数目的黑色节点，所以依然满足这个性质
    3. 情形3：如果父节点P和叔父节点U二者都是红色，（此时新插入节点N做为P的左子节点或右子节点都属于情形3，这里右图仅显示N做为P左子的情形）则我们可以将它们两个重绘为黑色并重绘祖父节点G为红色（用来保持性质5）。现在我们的新节点N有了一个黑色的父节点P。因为通过父节点P或叔父节点U的任何路径都必定通过祖父节点G，在这些路径上的黑节点数目没有改变。但是，红色的祖父节点G可能是根节点，这就违反了性质2，也有可能祖父节点G的父节点是红色的，这就违反了性质4。为了解决这个问题，我们在祖父节点G上递归地进行情形1的整个过程。（把G当成是新加入的节点进行各种情形的检查）
（待续）
3. 删除
（待续）

### 算法
#### 1. 一句话描述动态规划，举一个生活中的例子
1. 求出f(n)，只需要知道几个更小的f(c)。我们将求解f(c)称作求解f(n)的“子问题”。这就是DP（动态规划，dynamic programming）
2. 生活问题

    假设一个土豪，身上带了足够的1、5、10、20、50、100元面值的钞票。现在的目标是凑出某个金额w，需要用到尽量少的钞票。长期的生活经验表明，贪心策略是正确的。
    
    但是，如果我们换一组钞票的面值，贪心策略就也许不成立了。如果钞票面额分别是1、5、11，那么我们在凑出15的时候，贪心策略会出错：15=1×11+4×1（贪心策略使用了5张钞票）；15=3×5（正确的策略，只用3张钞票）
    
    贪心策略错在了“鼠目寸光”。贪心是一种只考虑眼前情况的策略。
    
    如果直接暴力枚举凑出w的方案，明显复杂度过高。太多种方法可以凑出w了，枚举它们的时间是不可承受的。我们现在来尝试找一下性质：
    
    w=15时，
    1. 如果取11，接下来就面对w=4的情况
    2. 如果取5，则接下来面对w=10的情况
    3. 如果取1，则接下来面对w=14的情况
    
    我们发现这些问题都有相同的形式：“给定w，凑出w所用的最少钞票是多少张？”
    
    用f(n)来表示“凑出n所需的最少钞票数量”。那么，
    1. 取11：cost = f(4) + 1 = 4 + 1 = 5
    2. 取5：cost = f(10) + 1 = 2 + 1 = 3
    3. 取1：cost = f(14) + 1 = 4 + 1 = 5  
    
    `f(n)`只与`f(n - 1)` `f(n - 5)` `f(n - 11)`相关，确切的说：`f(n) = min{f(n-1), f(n-5), f(n-11)} + 1`
    
    要求出f(n)，只需要求出几个更小的f值；既然如此，我们从小到大把所有的f(i)求出来就好了
    
    它与暴力的区别在于暴力枚举了“使用的硬币”，然而这属于冗余信息。要求出f(15)，只需要知道f(14),f(10),f(4)的值。其他信息并不需要。舍弃了冗余信息。我们只记录了对解决问题有帮助的信息——f(n).　　
    
    我们能这样干，取决于问题的性质：求出f(n)，只需要知道几个更小的f(c)。我们将求解f(c)称作求解f(n)的“子问题”。这就是DP（动态规划，dynamic programming）

### 项目
#### 1. 难点

#### 2. 如何进行断点复传

#### 3. 数据库设计中遇到的问题
1. wl case：时间排序，会有相同时间情况。用多参数排序
2. 大表翻页

### coding
#### 1. 实现开方函数